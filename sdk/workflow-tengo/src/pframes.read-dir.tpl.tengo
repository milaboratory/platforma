// read p-frame processor

self := import(":workdir-proc")
ll := import(":ll")
text := import("text")
slices := import(":slices")
smart := import(":smart")
json := import("json")
validation := import(":validation")


self.readFiles(func(inputs) {
	dInfo := {}

	args := inputs.args

	// search for .datainfo files
	for f in inputs.files {
		if text.has_suffix(f, ".datainfo") {
			dInfo[f] = f
		}
	}

	// @TODO assert .datainfo files are contained in the args
	return dInfo
})

_dataInfoSchemeJson := {
	partitionKeyLength: `number`,
	type: `string,regex=JsonPartitioned`,
	parts: {
		any: `string`
	}
}

_dataInfoSchemeBinary := {
	partitionKeyLength: `number`,
	type: `string,regex=BinaryPartitioned`,
	parts: {
		any: {
			index: `string`,
			values: `string`
		}
	}
}

_dataInfoScheme := [`or`, _dataInfoSchemeJson, _dataInfoSchemeBinary]


self.body(func(inputs) {

	args := inputs.args

	// columns
	outputs := {}
	for c in args.columns {

		name := c.name
		if is_undefined(name) {
			name = c.column
		}

		id := c.id
		if is_undefined(id) {
			id = name
		}

		dInfo := inputs["out/" + id + ".datainfo"].getDataAsJson()
		// validate dataInfo type
		validation.assertJsonSchema(dInfo, _dataInfoScheme)

		// p-column resource builder
		rType := { Name: "PColumnData/" + dInfo.type, Version: "1" }
		rData := { partitionKeyLength: dInfo.partitionKeyLength }
		rBuilder := smart.structBuilder(rType, json.encode(rData))

		for part, data in dInfo.parts {
			if dInfo.type == "BinaryPartitioned" {

				// pf data is always exported in out dir
				indexFile := self.saveFile("out/" + data.index)
				valuesFile := self.saveFile("out/" + data.values)

				rBuilder.createInputField(part + ".index").set(indexFile)
				rBuilder.createInputField(part + ".values").set(valuesFile)
			} else if dInfo.type == "JsonPartitioned" {

				valuesFile := self.saveFile("out/" + data)
				rBuilder.createInputField(part).set(valuesFile)
			}
		}

		outputs[name] = rBuilder.lockAndBuild()
	}

	return outputs
})
