/**
 * Library providing xsv <> p-frames conversion utils.
 */

validation := import(":validation")
constants := import(":pframes.constants")
objects := import(":objects")
smart := import(":smart")
render := import(":render")
maps := import(":maps")
util := import(":pframes.util")
pBuilder := import(":pframes.builder")
pframesSpec := import(":pframes.spec")
ll := import(":ll")
assets := import(":assets")
xsvIF := import(":pframes.xsv-import-file")
text := import("text")
execConstants := import(":exec.constants")
pt := import(":pt")
slices := import(":slices")
canonical := import(":canonical")

importXsvIfNullTpl := assets.importTemplate(":pframes.xsv-import-if-not-null")

/**
 * Calculate axes spec from pfconv spec
 */
getAxesSpec := func(spec) {
	axes := []
	for ax in spec.axes {
		axes = append(axes, ax.spec)
	}
	return axes
}

renderOps := func(defaults, ...ops) {
	o := { }

	for k, v in defaults {
		o[k] = v
	}

	if len(ops) > 0 {
		for k, v in ops[0] {
			o[k] = v
		}
	}
	return o
}

getColumnSpec := func(axesSpec, col) {
	spec := {
		kind: constants.KIND_P_COLUMN,
		axesSpec: axesSpec
	}

	for k, v in col.spec {
		spec[k] = v
	}

	return objects.deleteUndefined(spec)
}

/**
 * Imports xsv data into p-frame. The resulting map resource contains all columns specified in the params (column identifiers as
 * provided by the spec used as map keys). Resulting p-columns will be always single-partitioned at most.
 *
 * @param xsvFile: reference - a reference to a file
 * @param xsvType: string - either csv or tsv
 * @param spec: object - xsv conversion specification
 * @param ops: object - additional options
 *               {
 *                 dataOnly: boolean  - set to true to completely skip creation of specs
 *                 splitDataAndSpec: boolean  - if true, resulting map will have nested structures,
 *                                              with "spec" + "data" fields in nested maps
 *                 allowNullInput: boolean - if true, null input file is allowed and will return null resource
 *                 transpose: object - if specified, then the input table will be transposed
 *                            {
 *                              separator: string - (optional) use separator instead of inferring from the file extension
 *                              pAxisIdx: index - (optional) the index of the primary axis (column in the input xsv); default 0
 *                              pAxisName: string - (optional) the name of the primary axis (column name in the input xsv); default undefined
 *                              pAxisSearch: regex - (optional) the regex pattern of the name of the primary axis (column name in the input xsv); default undefined
 *                              pAxisNameOverride: string - (optional) override primary axis header in the output; default undefined
 *                              sAxisSearch: string - (optional) regex to filter secondary axis columns in the input table;
 *                              sAxisName: string - (optional) the name of the secondary axis (column name in the output xsv); default "Metric"
 *                              valueName: string - (optional) the name of the value column; default "Value"
 *                              separatorOverride: string - (optional) specify separator in the output (optional)
 *                            }
 *                 cpu: number - (optional) number of cores requested for command.
 *                 mem: number | string - (optional) amount of RAM in bytes or string with size suffix
 *                 queue: string - (optional) the name of the queue. Defaults to the light queue.
 *                 inputCache: duration - (optional) cache duration for execution inputs.
 *               }
 * @return map: reference - a reference to a map resource storing imported data.
 */
importFile := func(xsvFile, xsvType, spec, ...ops) {
	ll.assert(xsvType == "csv" || xsvType == "tsv", "expected one of [tsv, csv] types, found: " + xsvType)

	validation.assertType(spec, util.PFCONV_IMPORT_CFG_SCHEMA)

	allowNullInput := false
	if len(ops) > 0 {
		allowNullInput = ops[0].allowNullInput
	}

	if allowNullInput {
		return render.create(importXsvIfNullTpl, {
			xsvFile: xsvFile,
			params: {
				xsvType: xsvType,
				spec: spec,
				ops: [maps.merge(ops[0], { allowNullInput: undefined })]
			}
		}).output("result")
	}

	return xsvIF.importFile(xsvFile, xsvType, spec, ops...)
}

/**
 * Imports a map with xsv files into a p-frame. The resulting map resource contains all columns specified in the params (column identifiers as
 * provided by the spec used as map keys). Resulting p-columns may be double-partitioned.
 *
 * @param xsvMap: reference - a reference to a p-column resource map with xsv files
 * @param xsvType: string - either csv or tsv
 * @param spec: object - xsv conversion specification
 * @param ops: object - additional options
 *               {
 *                 dataOnly: boolean  - set to true to completely skip creation of specs
 *                 splitDataAndSpec: boolean  - if true, resulting map will have nested structures,
 *                                              with "spec" + "data" fields in nested maps
 *                 additionalAxesSpec: AxisSpec[]  - array of additional axes spec to prepend to
 *                                                   each column spec
 *                 transpose: object - if specified, then the input table will be transposed
 *                            {
 *                              separator: string - (optional) use separator instead of inferring from the file extension
 *                              pAxisIdx: index - (optional) the index of the primary axis (column in the input xsv); default 0
 *                              pAxisName: string - (optional) the name of the primary axis (column name in the input xsv); default undefined
 *                              pAxisSearch: regex - (optional) the regex pattern of the name of the primary axis (column name in the input xsv); default undefined
 *                              pAxisNameOverride: string - (optional) override primary axis header in the output; default undefined
 *                              sAxisSearch: string - (optional) regex to filter secondary axis columns in the input table;
 *                              sAxisName: string - (optional) the name of the secondary axis (column name in the output xsv); default "Metric"
 *                              valueName: string - (optional) the name of the value column; default "Value"
 *                              separatorOverride: string - (optional) specify separator in the output (optional)
 *                            }
 *                 cpu: number - (optional) number of cores requested for command.
 *                 mem: number | string - (optional) amount of RAM in bytes or string with size suffix
 *                 queue: string - (optional) the name of the queue. Defaults to the light queue.
 *                 inputCache: duration - (optional) cache duration for execution inputs.
 *               }
 * @return map: reference - a reference to a map resource storing imported data.
 */
importFileMap := func(xsvMap, xsvType, spec, ...ops) {

	importXsvMapTpl := assets.importTemplate(":pframes.xsv-import-map")

	ops := renderOps({
		dataOnly: false,
		splitDataAndSpec: false,
		additionalAxesSpec: [],
		transpose: undefined,
		inputCache: undefined
	}, ops...)

	// spec without any metadata (for caching purposes)
	decomposedSpec := util.decomposePfconvImportCfg(spec, { additionalAxesSpec: ops.additionalAxesSpec })
	pureSpec := decomposedSpec.purifiedCfg
	columnsSpec := decomposedSpec.columnsSpec

	templateOps := {
		dataOnly: true,
		transpose: ops.transpose
	}
	if !is_undefined(ops.cpu) {
		templateOps.cpu = ops.cpu
	}
	if !is_undefined(ops.mem) {
		templateOps.mem = ops.mem
	}
	if !is_undefined(ops.queue) {
		templateOps.queue = ops.queue
	}
	if !is_undefined(ops.inputCache) && ops.inputCache > 0 {
		templateOps.inputCache = ops.inputCache
	}

	r := render.createEphemeral(importXsvMapTpl, {
		xsvMap: xsvMap,
		xsvType: xsvType,
		spec: pureSpec,
		ops: templateOps
	})

	if ops.dataOnly && ops.splitDataAndSpec {
		ll.panic("Can't use both options dataOnly and splitDataAndSpec at the same time.")
	}

	result := {}
	axesSpec := getAxesSpec(spec)
	for c in spec.columns {
		id := util.xsvColumnId(c)
		if ops.dataOnly {
			result[id] = r.output(id)
		} else if ops.splitDataAndSpec {
			result[id] = {
				data: r.output(id),
				spec: columnsSpec[id]
			}
		} else {
			result[id + ".data"] = r.output(id)
			result[id + ".spec"] = columnsSpec[id]
		}
	}

	return result
}

/**
 * Export p-frame into xsv file
 *
 * @param pf: p-frame - a list of p-columns ({data, spec}) or a frame-like map of col.data col.spec entries
 * @param xsvType: string - "csv" or "tsv"
 * @param params: object - export params
 *                      {
 *                        naStr?: string     - String to represent NA and missing values of numeric types (Int, Long, Float, Double)
 *                                           - Default: "NaN"
 *                        nullStr?: string   - String to represent NA and missing values of text types (String, Bytes)
 *                                           - Default: "null"
 *                        joinType?: string  - Join type for columns with equal axes specifications
 *                                           - Options: "Full" | "Inner"
 *                                           - Default: "Full"
 *                      }
 * @param ops: object - additional options
 *               {
 *                 cpu: number - (optional) number of cores requested for command.
 *                 mem: number | string - (optional) amount of RAM in bytes or string with size suffix
 *                 queue: string - (optional) the name of the queue. Defaults to the light queue.
 *				   inputCache: duration - (optional) cache duration for execution inputs.
 *				 }
 * @return object: reference - a reference to exported xsv file.
 */
exportFrame := func(pf, xsvType, params, ...ops) {
	validation.assertType(params, util.PFCONV_EXPORT_CFG_SCHEMA)
	partialParams := objects.deleteUndefined({
		naStr: params.naStr,
		nullStr: params.nullStr,
		joinType: params.joinType
	})

	ops := renderOps({}, ops...)
	ll.assert(is_undefined(ops.partitions), "partitions option is no longer supported")

	runMetaInputs := {
		queue: ops.queue,
		cpu: ops.cpu,
		mem: ops.mem,
		inputCache: ops.inputCache
	}
	// Many blocks mistakengly put ops and params together, so we need to handle this gracefully
	if !is_undefined(params.queue) {
		runMetaInputs.queue = params.queue
		delete(params, "queue")
	}
	if !is_undefined(params.cpu) {
		runMetaInputs.cpu = params.cpu
		delete(params, "cpu")
	}
	if !is_undefined(params.mem) {
		runMetaInputs.mem = params.mem
		delete(params, "mem")
	}
	if !is_undefined(params.inputCache) {
		runMetaInputs.inputCache = params.inputCache
		delete(params, "inputCache")
	}

	if len(partialParams) < len(params) {
		ll.panic("Some params are not supported: %v", params)
	}

	if is_array(pf) {
		// transform into .data .spec map

		pfBuilder := pBuilder.pFrameBuilder()
		i := 0
		for col in pf {
			ll.assert(!is_undefined(col.spec), "expected array of {spec, data} maps as a list of columns, but spec is undefined for: ", col)
			ll.assert(!is_undefined(col.data), "expected array of {spec, data} maps as a list of columns, but data is undefined for: ", col)
			pfBuilder.add(string(i), col.spec, col.data)
			i = i + 1
		}
		pf = pfBuilder.build()
	} else if util.isStructuredPfMap(pf) {
		pfBuilder := pBuilder.pFrameBuilder()
		for key, value in pf {
			pfBuilder.add(key, value.spec, value.data)
		}
		pf = pfBuilder.build()
	} else if smart.isResource(pf) {
		if !pf.checkResourceType(constants.RTYPE_P_FRAME) {
			ll.panic("Unexpected resource type: %s", pf.info().Type.Name)
		}
	} else if !util.isFlatPfMap(pf) && !smart.isReference(pf) {
		ll.panic("Unexpected p-frame format: %s", pf)
	}

	resultFile := "result." + xsvType

	columnEntries := []
	rawColumns := []
	maps.forEach(util.pFrameToColumnsMap(pf), func(frameUniqueColumnId, columnInfo) {
		columnEntries = append(columnEntries, pt.p.column(frameUniqueColumnId, columnInfo))
		rawColumns = append(rawColumns, { id: frameUniqueColumnId, spec: columnInfo.spec })
	})

	frameInput := undefined
	if params.joinType == "Inner" {
		frameInput = pt.p.inner(columnEntries...)
	} else {
		frameInput = pt.p.full(columnEntries...)
	}

	numericSelector := pt.sc.numeric()
	if is_string(params.naStr) {
		numericSelector = numericSelector.fillNull(params.naStr)
	}
	stringSelector := pt.sc.string()
	if is_string(params.nullStr) {
		stringSelector = stringSelector.fillNull(params.nullStr)
	}

	specDistiller := pframesSpec.createSpecDistiller(slices.map(rawColumns, func(c) { return c.spec }))
	canonicalMap := {}
	uniqueAxes := []
	for column in rawColumns {
		for axis in column.spec.axesSpec {
			distilledAxis := specDistiller.distill(axis)
			canonicalizedAxisSpec := canonical.encode(distilledAxis)
			if is_undefined(canonicalMap[canonicalizedAxisSpec]) {
				canonicalMap[canonicalizedAxisSpec] = true
				distilledAxis.label = axis.annotations["pl7.app/label"]
				uniqueAxes = append(uniqueAxes, distilledAxis)
			}
		}
	}

	columnSelectors := []
	for axis in uniqueAxes {
		label := axis.label
		delete(axis, "label")
		columnSelectors = append(columnSelectors, pt.sc.axis(axis).alias(label))
	}
	for column in rawColumns {
		columnSelectors = append(columnSelectors, pt.col(column.id).alias(column.spec.annotations["pl7.app/label"]))
	}

	wf := pt.workflow()
	if runMetaInputs.queue == execConstants.LIGHT_QUEUE {
		wf = wf.inLightQueue()
	} else if runMetaInputs.queue == execConstants.MEDIUM_QUEUE {
		wf = wf.inMediumQueue()
	} else if runMetaInputs.queue == execConstants.HEAVY_QUEUE {
		wf = wf.inHeavyQueue()
	} else if runMetaInputs.queue == execConstants.UI_TASKS_QUEUE {
		wf = wf.inUiQueue()
	} else if !is_undefined(runMetaInputs.queue) {
		ll.panic("Unsupported queue: %v", runMetaInputs.queue)
	}
	if !is_undefined(runMetaInputs.cpu) {
		wf = wf.cpu(runMetaInputs.cpu)
	}
	if !is_undefined(runMetaInputs.mem) {
		wf = wf.mem(runMetaInputs.mem)
	}
	if !is_undefined(runMetaInputs.inputCache) {
		wf = wf.cacheInputs(runMetaInputs.inputCache)
	}
	wf.frame(frameInput).
		select(numericSelector, stringSelector).
		select(columnSelectors...).
		save(resultFile)

	result := wf.run()
	return result.getFile(resultFile)
}

export ll.toStrict({
	importFile: importFile,
	importFileMap: importFileMap,
	exportFrame: exportFrame
})
