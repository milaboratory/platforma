/**
 * Working with p-frames
 */

ll := import(":ll")
maps := import(":maps")
smart := import(":smart")
slices := import(":slices")
sets := import(":sets")
assets := import(":assets")
render := import(":render")
builder := import(":pframes.builder")
pUtil := import(":pframes.util")
pSpec := import(":pframes.spec")
validation := import(":validation")
constants := import(":pframes.constants")
xsvBuilder := import(":pframes.xsv-builder")
pColumnData := import(":pframes.data")

llProcessTpl := assets.importTemplate(":pframes.process-pcolumn-data")

// Schema for TsvContent settings validation
TSV_CONTENT_SETTINGS_SCHEMA := {
	"axes": [{
		"column": "string",
		"spec": {
			"type": "string,regex=Int|Long|Float|Double|String",
			"name,?": "string",
			"domain,?": { "any": "string" },
			"annotations,?": { "any": "string" }
		}
	}],
	"columns": [{
		"column": "string",
		"id,?": "string",
		"spec": {
			"valueType": "string,regex=Int|Long|Float|Double|String",
			"name,?": "string",
			"domain,?": { "any": "string" },
			"annotations,?": { "any": "string" }
		}
	}]
}

/**
 * Given a reference to the p-frame, converts all inner resource files into resources that can be
 * downloaded from the UI side.
 */
exportFrame := func(pf) {
	return render.createEphemeral(assets.importTemplate(":pframes.export-pframe"), { pf: pf }).output("result")
}

/**
 * Export single PColumn data
 */
exportColumnData := func(data) {
	return render.createEphemeral(assets.importTemplate(":pframes.export-single-pcolumn"), { data: data }).output("result")
}

/**
 * @deprecated pframes.pColumnResourceMapDataBuilder is not supported any more; use pcolumn.resourceMapBuilder
 * Creates a builder for a resource map p-column's data.
 */
pColumnResourceMapDataBuilder := func(keyLength) {
	ll.panic("pframes.pColumnResourceMapDataBuilder is not supported any more; use pcolumn.resourceMapBuilder")
}

__primitiveValueTypes := { "Int": true, "Long": true, "Float": true, "Double": true, "String": true, "Bytes": true }

/**
 * Constructs a mapping or aggregation pipeline for a given input PColumn and returns a specialized
 * output object for accessing the processing results.
 *
 * === Body Template Contract ===
 *
 *   Inputs:
 *     "__key__"   - When passKey is true, contains the JSON representation of the group/element key:
 *                     - Without aggregation: represents a single key
 *                     - With aggregation: represents all keys in positions not specified by indices
 *                   Not provided if passKey is false or omitted from ops
 *     "__aggregation_axes_spec__"
 *                 - When passAggregationAxesSpec is true, contains the axes specification for aggregation
 *                     Can be used to adapt body behavior when optional aggregation axes are unmatched
 *                   Not provided if passAggregationAxesSpec is false or omitted from ops
 *     "__aggregation_axes_names__"
 *                 - When passAggregationAxesNames is true, contains just the names of aggregation axes
 *                     as a simple array of strings, without domains, annotations, etc.
 *                   Not provided if passAggregationAxesNames is false or omitted from ops
 *     "__distilled_aggregation_spec__"
 *                 - When passDistilledAggregationAxesSpec is true, contains the *distilled* column specification containing only the aggregation axes.
 *                   Distilled specs remove non-discriminative domains and all annotations.
 *                   Useful for stable identification of aggregation axes regardless of minor spec variations.
 *                   Not provided if passDistilledAggregationAxesSpec is false or omitted from opts.
 *     "__value__" - Content depends on aggregation setting:
 *                     - Without aggregation (mapping mode): single value/resource reference (only for ResourceMap PColumns, i.e., non-primitive valueTypes).
 *                     - With aggregation: "PColumnData/*" resource containing all records in current group. The exact type
 *                       (ResourceMap, JsonPartitioned, BinaryPartitioned) matches the inferred type of the input data.
 *     ...extra    - Additional values/references passed via the options.extra parameter
 *                   are forwarded to the template unchanged
 *
 * === Parameters ===
 *
 * @param input         Primary input column data and specifications
 *
 *                      Required structure:
 * 							{
 * 							 	// PColumn specifications (must be explicit, not a reference)
 * 							 	spec: <PColumnSpec>,
 *
 * 							 	// Reference to the data resource. Supported underlying types:
 *                              // - PColumnData/ResourceMap (inferred for non-primitive valueTypes like File, Resource, etc.)
 *                              // - PColumnData/JsonPartitioned (inferred for primitive valueTypes: Int, Long, Float, Double, String, Bytes)
 *                              // - PColumnData/BinaryPartitioned (inferred for primitive valueTypes)
 *                              // Partitioned types (Json/Binary) require aggregate option to be set.
 * 							 	data: <resource ref>
 *							}
 *
 * @param bodyTpl       Template executed for each iteration (see contract above)
 * @param outputs 		Array of output configurations to collect from rendered templates
 *
 *                  Common fields for all types:
 *                     {
 *                       name:  string       // Output name
 *                       path?: string[]     // [Optional] Path to access data in body template result
 *                                           // First element is used as the output name in renderResult.output()
 *                                           // First element can also be an object with {name: string, optional?: bool}
 *                                           // Remaining elements are passed to getFutureInputField and can be:
 *                                           //   - string: field name to access
 *                                           //   - object: {name: string, optional?: bool, eph?: bool} to configure field access
 *                                           //   - mixed array of strings and objects to traverse a nested path
 *                                           // Defaults to [name] if omitted
 *                       keepNulls?: boolean // Relevant if optional flag is used in path.
 *                                           // If true, keys for which output was not found will be present in the output
 *                                           // with null value. If false or not specified, such keys will not be present.
 *                     }
 *
 *                  Available types:
 *                    | {
 *                        type: "Resource",     // Single resource output
 *                        spec: PColumnSpec     // Result column spec (must have zero axes specs,
 *                                              // input axes specs added automatically)
 *                      }
 *                    | {
 *                        type: "ResourceMap",  // ResourceMap output
 *                        spec: PColumnSpec     // Result column spec (list only axes specs
 *                                              // produced by body template, input axes added automatically)
 *                      }
 *                    | {
 *                        type: "BinaryPartitioned" | "JsonPartitioned",
 *                                              // Partitioned Json/Binary PColumn data
 *                        spec: PColumnSpec     // Result column spec (list only axes specs
 *                                              // produced by body template, input axes added automatically)
 *                        partitionKeyLength: number
 *                                              // Expected partition length per operation
 *                      }
 *                    | {
 *                        type: "Xsv",          // CSV/TSV formatted text file for xsv conversion
 *						  xsvType: "tsv"|"csv", // Expected file format
 *                        settings: object,     // Xsv conversion specification
 *                        cpu: number,          // Override CPU for this output
 *                        mem: number | string, // Override MEM for this output
 *                        queue: string         // Override queue for this output
 *                      }
 *                    | {
 *                        type: "TsvContent",   // TSV content parsed to JSON PColumn data
 *                        settings: {           // TSV parsing specification
 *                          axes: [             // Array of axis definitions
 *                            {
 *                              column: string, // TSV column name
 *                              spec: AxisSpec  // Axis specification (type, name, domain, etc.)
 *                            }
 *                          ],
 *                          columns: [          // Array of column definitions
 *                            {
 *                              column: string, // TSV column name
 *                              id?: string,    // Optional column identifier for output map
 *                              spec: PColumnSpec // Column specification (valueType, name, domain, etc.)
 *                            }
 *                          ]
 *                        }
 *                      }
 *
 * @param opts 			Optional additional settings
 *
 *                    {
 *                      traceSteps?: array      // Array of trace steps to add to output specs
 *                                              // Each step should be an object with type, id, importance and label
 *
 *                      overrideTrace?: boolean // If true, override existing trace annotations in output specs.
 *                                              // If false, preserve existing trace annotations.
 *                                              // If not specified, defaults to true when traceSteps is provided, false otherwise.
 *
 *                      aggregate?: AxisMatcher[],
 *                                              // If specified, selected axes are combined and
 *                                              // passed to each iteration as a group. These axes
 *                                              // won't be automatically added to output specs
 *                                              // Each AxisMatcher can have an optional 'anonymize: true' flag to anonymize
 *                                              // key elements for deduplication and recovery. The behavior depends on the
 *                                              // number of axes marked for anonymization within the aggregation group:
 *                                              //
 *                                              //  - **Single axis**: its key element is **replaced** with an anonymized key.
 *                                              //  - **Multiple axes**: their key elements are **removed**, and a single combined
 *                                              //    anonymized key is **appended** to the group key.
 *                                              //
 *                                              // Examples:
 *                                              //   - "pl7.app/sequencing/readIndex"
 *                                              //   - { name: "pl7.app/sequencing/readIndex" }
 *                                              //   - { type: "String", name: "pl7.app/sequencing/lane" }
 *                                              //   - { type: "String", name: "pl7.app/sequencing/lane", optional: true }
 *                                              //   - { type: "String", name: "pl7.app/rna-seq/geneId", domain: { "pl7.app/species": "homo-sapiens" } }
 *                                              // With optional: true, matcher won't error if unmatched
 *                                              // Use passAggregationAxesSpec or passDistilledAggregationAxesSpec for custom handling in body template
 *
 *                      passKey?: boolean       // Pass __key__ to body template if true
 *
 *                      passAggregationAxesSpec?: boolean
 *                                              // Pass full aggregation axes specs to body template
 *                                              // via __aggregation_axes_spec__ input
 *
 *                      passAggregationAxesNames?: boolean
 *                                              // Pass array of aggregation axes names to body template
 *                                              // via __aggregation_axes_names__ input
 *
 *                      passDistilledAggregationSpec?: boolean
 *                                              // Pass *distilled* aggregation axes specs (no annotations, only
 *                                              // discriminative domains) in a distilled PColumnSpec via __distilled_aggregation_spec__ input
 *
 *                      stepCache?: number      // Cache results of each iteration for a specified duration.
 *                                              // Use constants from the 'times' module (e.g., `30 * times.seconds`).
 *                                              // Caches on iteration level, both before and after xsv conversion.
 *                                              // Useful for resuming after premature termination or restarts.
 *
 *                      extra?: Map<string, Ref>,
 *                                              // Additional parameters passed to each body invocation
 *                                              // Keys match template input names
 *
 *                      metaExtra?: Map<string, Ref>,
 *                                              // Additional meta parameters passed to each body invocation
 *                                              // Keys match template input names
 *
 *                      isEphemeral?: boolean   // Whether to render mapping template in ephemeral mode
 *                                              // Defaults to false if omitted, template will be rendered
 *                                              // as pure resource
 *                      cpu: number,            // Global CPU setting for XSV imports
 *                      mem: number | string,   // Global MEM setting for XSV imports
 *                      queue: string           // Global queue setting for XSV imports
 *                    }
 *
 * === Return ===
 *
 * @returns Object with methods for retrieving processing results
 *          See source code for method documentation and signatures
 */
processColumn := func(input, bodyTpl, outputs, ...opts) {
	if len(opts) == 0 {
		opts = {}
	} else if len(opts) == 1 {
		opts = opts[0]
	} else {
		ll.panic("too many arguments")
	}

	if is_undefined(input.spec) {
		ll.panic("no input spec provided")
	}

	if !smart.isReference(input.data) {
		ll.panic("input data should be a reference to a field or resource")
	}

	validation.assertType(input.spec, pSpec.P_COLUMN_SPEC_SCHEMA)

	if is_undefined(opts.passKey) {
		opts.passKey = false
	}

	if is_undefined(opts.passAggregationAxesSpec) {
		opts.passAggregationAxesSpec = false
	}

	if is_undefined(opts.passAggregationAxesNames) {
		opts.passAggregationAxesNames = false
	}

	if is_undefined(opts.passDistilledAggregationSpec) {
		opts.passDistilledAggregationSpec = false
	}

	if is_undefined(opts.isEphemeral) {
		opts.isEphemeral = false
	}

	if (opts.passAggregationAxesSpec || opts.passAggregationAxesNames || opts.passDistilledAggregationSpec) && is_undefined(opts.aggregate) {
		ll.panic("can't use passAggregationAxesSpec, passAggregationAxesNames or passDistilledAggregationSpec without aggregate")
	}

	// Initialize trace if traceSteps provided
	trace := undefined
	if !is_undefined(opts.traceSteps) || !is_undefined(input.spec.annotations[pSpec.A_TRACE]) {
		trace = pSpec.makeTrace(input.spec, (opts.traceSteps ? opts.traceSteps : [])...)
	}

	// Set overrideTrace with smart defaults
	overrideTrace := opts.overrideTrace
	if is_undefined(overrideTrace) {
		// Default to true if traceSteps is provided, false otherwise
		overrideTrace = !is_undefined(opts.traceSteps)
	}

	// JSON params passed as a single resource to the template
	processTemplateParams := {
		eph: opts.isEphemeral,
		passKey: opts.passKey
	}

	if !is_undefined(opts.stepCache) && opts.stepCache > 0 {
		processTemplateParams.stepCache = opts.stepCache
	}

	if !is_undefined(opts.cpu) {
		processTemplateParams.cpu = opts.cpu
	}
	if !is_undefined(opts.mem) {
		processTemplateParams.mem = opts.mem
	}
	if !is_undefined(opts.queue) {
		processTemplateParams.queue = opts.queue
	}

	// Infer if data is likely partitioned based on valueType
	// Primitive types are assumed to use partitioned storage (Json/Binary)
	isPotentiallyPartitioned := __primitiveValueTypes[input.spec.valueType]

	extra := opts.extra
	if is_undefined(extra) {
		extra = {}
	}

	metaExtra := opts.metaExtra
	if is_undefined(metaExtra) {
		metaExtra = {}
	}

	iterationAxesSpec := copy(input.spec.axesSpec)
	// For partitioned data, the underlying template determines key length internally.
	// For ResourceMap, we pass the expected length based on the spec.
	if !isPotentiallyPartitioned {
		processTemplateParams.expectedKeyLength = len(input.spec.axesSpec)
	}

	if !is_undefined(opts.aggregate) {
		aggregationIndices := pSpec.matchAxes(input.spec.axesSpec, opts.aggregate)
		processTemplateParams.aggregationIndices = aggregationIndices

		// Collect indices of axes to be anonymized within the aggregation group
		anonymizationIndices := []
		anonymizedMatchers := slices.filter(opts.aggregate, func(m) { return is_map(m) && m.anonymize })

		nonAnonymizedAggregationIndices := undefined

		if len(anonymizedMatchers) > 0 {
			anonymizedAxesIndices := pSpec.matchAxes(input.spec.axesSpec, anonymizedMatchers)
			anonymizedIndicesSet := sets.fromSlice(anonymizedAxesIndices)

			nonAnonymizedAggregationIndices = []
			for i, aggIdx in aggregationIndices {
				if anonymizedIndicesSet[aggIdx] {
					anonymizationIndices = append(anonymizationIndices, i)
				} else {
					nonAnonymizedAggregationIndices = append(nonAnonymizedAggregationIndices, aggIdx)
				}
			}

			if len(anonymizationIndices) > 0 {
				processTemplateParams.anonymizationIndices = anonymizationIndices
			}
		} else {
			nonAnonymizedAggregationIndices = aggregationIndices
		}


		// calculate iteration axes spec
		groupAxesIndices := pUtil.calculateGroupAxesIndices(len(input.spec.axesSpec), aggregationIndices)
		iterationAxesSpec = []
		for i in groupAxesIndices {
			iterationAxesSpec = append(iterationAxesSpec, input.spec.axesSpec[i])
		}

		if opts.passAggregationAxesSpec {
			aggregationAxesSpec := []
			for i in nonAnonymizedAggregationIndices {
				aggregationAxesSpec = append(aggregationAxesSpec, input.spec.axesSpec[i])
			}

			extra[constants.AGGREGATION_AXES_SPEC_FIELD_NAME] = smart.createJsonResource(aggregationAxesSpec)
		}

		if opts.passAggregationAxesNames {
			aggregationAxesNames := []
			for i in nonAnonymizedAggregationIndices {
				aggregationAxesNames = append(aggregationAxesNames, input.spec.axesSpec[i].name)
			}

			extra[constants.AGGREGATION_AXES_NAMES_FIELD_NAME] = smart.createJsonResource(aggregationAxesNames)
		}

		if opts.passDistilledAggregationSpec {
			distiller := pSpec.createSpecDistiller([input.spec])
			distilledSpec := distiller.distill(input.spec)

			passSpec := maps.deepTransform(distilledSpec, {
				axesSpec: func(axesSpec) {
					aggregationAxesSpec := []
					for i in nonAnonymizedAggregationIndices {
						aggregationAxesSpec = append(aggregationAxesSpec, axesSpec[i])
					}
					return aggregationAxesSpec
				}
			})

			extra[constants.DISTILLED_AGGREGATION_SPEC_FIELD_NAME] = smart.createJsonResource(passSpec)
		}
	}

	processedOutputs := []
	outputSpecs := {}
	outputsMap := {}
	for output in outputs {
		// map output name to output settings provided in input
		outputsMap[output.name] = output
		if output.type == "Resource" || output.type == "BinaryPartitioned" || output.type == "JsonPartitioned" {
			spec := maps.merge(output.spec, { axesSpec: copy(iterationAxesSpec) + copy(output.spec.axesSpec) })
			if !is_undefined(trace) {
				spec = trace.inject(spec, {override: overrideTrace})
			}
			outputSpecs[output.name] = spec
			processedOutputs = append(processedOutputs, maps.merge(output, {spec: undefined })) // removing spec field
		} else if output.type == "ResourceMap" {
			processedOutputs = append(processedOutputs, maps.merge(output,
				{ keyLength: len(output.spec.axesSpec), spec: undefined }))
			spec := maps.merge(output.spec, { axesSpec: copy(iterationAxesSpec) + copy(output.spec.axesSpec) })
			if !is_undefined(trace) {
				spec = trace.inject(spec, {override: overrideTrace})
			}
			outputSpecs[output.name] = spec
		} else if output.type == "Xsv" {
			if is_undefined(output.settings) {
				ll.panic("settings are required for Xsv output")
			}
			decomposition := pUtil.decomposePfconvImportCfg(output.settings, {
				additionalAxesSpec: iterationAxesSpec
			})
			purifiedPfconvCfg := decomposition.purifiedCfg
			columnsSpec := decomposition.columnsSpec
			if !is_undefined(trace) {
				for columnName, spec in columnsSpec {
					columnsSpec[columnName] = trace.inject(spec, {override: overrideTrace})
				}
			}
			outputSpecs[output.name] = columnsSpec
			processedOutputs = append(processedOutputs, maps.merge(output,
				{
					settings: purifiedPfconvCfg,
					flattenWithDelimiter: "/"
				}))
		} else if output.type == "TsvContent" {
			validation.assertType(output.settings, TSV_CONTENT_SETTINGS_SCHEMA, "Invalid TsvContent settings")

			// Transform settings to parse template format using slices.map
			transformedSettings := {
				axes: slices.map(output.settings.axes, func(axis) {
					return {
						name: axis.column,
						type: axis.spec.type
					}
				}),
				columns: slices.map(output.settings.columns, func(column) {
					transformedColumn := {
						name: column.column,
						type: column.spec.valueType
					}
					if !is_undefined(column.id) {
						transformedColumn.id = column.id
					}
					return transformedColumn
				})
			}

			// Build output specs for each column
			columnsSpec := {}
			axesSpec := copy(iterationAxesSpec)
			for axis in output.settings.axes {
				axesSpec = append(axesSpec, axis.spec)
			}

			for column in output.settings.columns {
				columnId := column.id
				if is_undefined(columnId) {
					columnId = column.column
				}
				spec := maps.merge(column.spec, { axesSpec: axesSpec, kind: "PColumn" })
				if !is_undefined(trace) {
					spec = trace.inject(spec, {override: overrideTrace})
				}
				columnsSpec[columnId] = spec
			}

			outputSpecs[output.name] = columnsSpec
			processedOutputs = append(processedOutputs, maps.merge(output, {
				settings: transformedSettings,
				flattenWithDelimiter: "/"
			}))
		} else {
			ll.panic("unknown output type: " + output.type)
		}
	}
	processTemplateParams.outputs = processedOutputs

	renderInputs := {
		params: smart.createJsonResource(processTemplateParams),
		body: bodyTpl,
		data: input.data
	}

	for k, v in extra {
		renderInputs["__extra_" + k] = v
	}

	for k, v in metaExtra {
		renderInputs["__meta_" + k] = v
	}

	renderResult := render.createEphemeral(llProcessTpl, renderInputs)

	self := undefined
	self = ll.toStrict({
		renderResult: renderResult,

		/**
		 * Returns output spec for the given output name and optional column name
		 *
		 * For normal outputs (Resource, ResourceMap, BinaryPartitioned, JsonPartitioned),
		 * only the output name should be provided.
		 * For Xsv and TsvContent outputs, both output name and column name should be provided.
		 *
		 * @param name - Name of the output
		 * @param column - Optional. For Xsv and TsvContent outputs, name of the column
		 * @returns Output spec
		 */
		outputSpec: func(name, ...column) {
			output := outputsMap[name]
			if is_undefined(output) {
				ll.panic("unknown output: " + name)
			}

			spec := outputSpecs[name]
			if output.type == "Xsv" || output.type == "TsvContent" {
				if len(column) != 1 {
					ll.panic("column name must be provided for " + output.type + " output")
				}
				columnName := column[0]
				spec = spec[columnName]
				if is_undefined(spec) {
					ll.panic("unknown column: " + columnName)
				}
				return spec
			} else {
				if len(column) > 0 {
					ll.panic("column name should not be provided for non-Xsv/TsvContent output")
				}
				return spec
			}
		},

		/**
		 * Returns data resource for the given output name and optional column name
		 *
		 * For normal outputs (Resource, ResourceMap, BinaryPartitioned, JsonPartitioned),
		 * only the output name should be provided.
		 * For Xsv and TsvContent outputs, both output name and column name should be provided.
		 *
		 * @param name - Name of the output
		 * @param column - Optional. For Xsv and TsvContent outputs, name of the column
		 * @returns data resource
		 */
		outputData: func(name, ...column) {
			output := outputsMap[name]
			if is_undefined(output) {
				ll.panic("unknown output: " + name)
			}

			if output.type == "Xsv" || output.type == "TsvContent" {
				if len(column) != 1 {
					ll.panic("column name must be provided for " + output.type + " output")
				}
				return renderResult.output(name + "/" + column[0])
			} else {
				if len(column) > 0 {
					ll.panic("column name should not be provided for non-Xsv/TsvContent output")
				}
				return renderResult.output(name)
			}
		},

		/**
		 * Returns both data resource and spec for the given output name and optional column name
		 *
		 * For normal outputs (Resource, ResourceMap, BinaryPartitioned, JsonPartitioned),
		 * only the output name should be provided.
		 * For Xsv and TsvContent outputs, both output name and column name should be provided.
		 *
		 * @param name - Name of the output
		 * @param column - Optional. For Xsv and TsvContent outputs, name of the column
		 * @returns {data: Resource, spec: PColumnSpec} Object containing both data resource and spec
		 */
		output: func(name, ...column) {
			output := outputsMap[name]
			if is_undefined(output) {
				ll.panic("unknown output: " + name)
			}

			if output.type == "Xsv" || output.type == "TsvContent" {
				if len(column) != 1 {
					ll.panic("column name must be provided for " + output.type + " output")
				}
				columnName := column[0]
				spec := outputSpecs[name][columnName]
				if is_undefined(spec) {
					ll.panic("unknown column: " + columnName)
				}
				return {
					data: renderResult.output(name + "/" + columnName),
					spec: spec
				}
			} else {
				if len(column) > 0 {
					ll.panic("column name should not be provided for non-Xsv/TsvContent output")
				}
				return {
					data: renderResult.output(name),
					spec: outputSpecs[name]
				}
			}
		},

		/**
		 * Returns a PFrame containing all columns from an Xsv or TsvContent output
		 *
		 * @param name - Name of the Xsv or TsvContent output
		 * @returns PFrame containing all columns from the output
		 */
		xsvOutputFrame: func(name) {
			output := outputsMap[name]
			if is_undefined(output) {
				ll.panic("unknown output: " + name)
			}

			if output.type != "Xsv" && output.type != "TsvContent" {
				ll.panic("outputFrame can only be used with Xsv or TsvContent outputs")
			}

			builder := builder.pFrameBuilder()
			for columnName, spec in outputSpecs[name] {
				builder.add(columnName, spec, renderResult.output(name + "/" + columnName))
			}
			return builder.build()
		},

		/**
		 * Adds all outputs to the provided pframe builder
		 *
		 * @param builder - The pframe builder to which outputs will be added
		 * @param ...separator - Optional separator for joining Xsv output and column names, defaults to "."
		 * @returns The provided builder for chaining
		 */
		addAllOutputsToBuilder: func(builder, ...separator) {
			sep := "."
			if len(separator) > 0 {
				sep = separator[0]
			}

			maps.forEach(outputsMap, func(name, output) {
				if output.type == "Xsv" || output.type == "TsvContent" {
					// For Xsv and TsvContent outputs, add each column with name prefixed
					for columnName, spec in outputSpecs[name] {
						builder.add(
							name + sep + columnName,
							spec,
							renderResult.output(name + "/" + columnName)
						)
					}
				} else {
					// For other outputs, add directly
					builder.add(
						name,
						outputSpecs[name],
						renderResult.output(name)
					)
				}
			})

			return builder
		},

		/**
		 * Returns a PFrame containing all results, flattening Xsv and TsvContent outputs using the provided separator
		 *
		 * @param ...xsvNameSeparator - Optional separator for joining Xsv and TsvContent output and column names, defaults to "."
		 * @returns PFrame containing all results
		 */
		allOutputsFrame: func(...xsvNameSeparator) {
			builder := builder.pFrameBuilder()
			self.addAllOutputsToBuilder(builder, xsvNameSeparator...)
			return builder.build()
		},

		/**
		 * Returns sorted list of all available output names
		 *
		 * @returns Array of output names
		 */
		listOutputs: func() {
			return maps.getKeys(outputsMap)
		},

		/**
		 * Checks if given output is of Xsv type
		 *
		 * @param name - Output name to check
		 * @returns true if output is Xsv, false otherwise
		 */
		isXsvOutput: func(name) {
			output := outputsMap[name]
			if is_undefined(output) {
				ll.panic("unknown output: " + name)
			}
			return output.type == "Xsv"
		},

		/**
		 * Returns sorted list of column names for given Xsv or TsvContent output
		 *
		 * @param name - Xsv or TsvContent output name
		 * @returns Array of column names
		 */
		listXsvColumns: func(name) {
			output := outputsMap[name]
			if is_undefined(output) {
				ll.panic("unknown output: " + name)
			}
			if output.type != "Xsv" && output.type != "TsvContent" {
				ll.panic("output is not Xsv or TsvContent: " + name)
			}

			return maps.getKeys(outputSpecs[name])
		},

		/**
		 * Adds all columns from an Xsv or TsvContent output to the provided pframe builder with a prefix
		 *
		 * @param builder - The pframe builder to which columns will be added
		 * @param outputName - Name of the Xsv or TsvContent output to use
		 * @param prefix - Prefix to add to each column name (can be empty string)
		 * @returns The provided builder for chaining
		 */
		addXsvOutputToBuilder: func(builder, outputName, prefix) {
			for columnName in self.listXsvColumns(outputName) {
				builder.add(
					prefix + columnName,
					self.outputSpec(outputName, columnName),
					self.outputData(outputName, columnName)
				)
			}

			return builder
		}


	})

	return self
}

export ll.toStrict({
	parseData: pColumnData.parseData,
	processColumn: processColumn,
	exportFrame: exportFrame,
	pFrameBuilder: builder.pFrameBuilder,
	exportColumnData: exportColumnData,
	pColumnResourceMapDataBuilder: pColumnResourceMapDataBuilder,
	tsvFileBuilder: func() { return xsvBuilder.xsvFileBuilder("tsv") },
	csvFileBuilder: func() { return xsvBuilder.xsvFileBuilder("csv") }
})
