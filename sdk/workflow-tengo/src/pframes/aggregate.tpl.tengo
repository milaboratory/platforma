// pframes ll aggregate

self := import(":tpl")

ll := import(":ll")
render := import(":render")
smart := import(":smart")
pConstants := import(":pframes.constants")
pUtil := import(":pframes.util")
xsv := import(":pframes.xsv")

json := import("json")

self.awaitState("InputsLocked")
self.awaitState("data", "InputsLocked")
self.awaitState("params", "ResourceReady")

self.body(func(inputs) {

	// parameters of aggregation
	//   indices: int[]
	//   eph: bool
	//   outputs: (string)[]
	params := inputs.params

	if is_undefined(params) {
		ll.panic("Params is not defined")
	}

	if !is_map(params) {
		ll.panic("Params have wrong type, or nor ready yet: %v", params)
	}

	indices := params.indices
	eph := params.eph
	outputs := params.outputs

	if !is_array(outputs) || len(outputs) == 0 {
		ll.panic("Absent, empty or malformed outputs list: %v", params)
	}

	// map of resources to aggregate over
	data := inputs.data

	// template implementing aggregation body
	body := inputs.body

	if is_undefined(data) {
		ll.panic("Data is not defined")
	}

	if is_undefined(body) {
		ll.panic("Body is not defined")
	}

	extraInputs := {}
	for name, field in inputs {
		if name != "params" && name != "data" && name != "body" {
			if name[:8] != "__extra_" {
				ll.panic("Unexpected input: %v", name)
			}
			extraInputs[name[8:]] = field
		}
	}

	if data.checkResourceType(pConstants.RTYPE_P_COLUMN_DATA_RESOURCE_MAP) {
		meta := data.getDataAsJson()

		// calculating group indices
		groupIndices := []
		for i:=0; i<meta.keyLength; i++ {
			groupIndices = append(groupIndices, i)
		}
		for j:=len(indices)-1; j>=0; j-- {
			splice(groupIndices, indices[j], 1)
		}
		groupKeyLength := len(groupIndices)
		groupElementKeyLength := len(indices)

		// group key -> group resource
		groups := {}

		for sKey, field in data.inputs() {
			key := json.decode(sKey)

			groupKey := []
			for i in groupIndices {
				groupKey = append(groupKey, key[i])
			}

			inGroupKey := []
			for i in indices {
				inGroupKey = append(inGroupKey, key[i])
			}

			sGroupKey := json.encode(groupKey)
			sInGroupKey := json.encode(inGroupKey)

			group := groups[sGroupKey]
			if is_undefined(group) {
				group = smart.structBuilder(
					pConstants.RTYPE_P_COLUMN_DATA_RESOURCE_MAP,
					json.encode({ keyLength: groupElementKeyLength })
				)
				groups[sGroupKey] = group
			}
			group.createInputField(sInGroupKey).set(field)
		}

		outputMaps := {}

		for output in outputs {
			if !is_map(output) {
				ll.panic("malformed output: %v", output)
			}
			if output.type == "Resource" {
				outputMaps[output.name] = smart.structBuilder(
					pConstants.RTYPE_P_COLUMN_DATA_RESOURCE_MAP,
					json.encode({ keyLength: groupKeyLength })
				)
			} else if output.type == "ResourceMap" {
				outputMaps[output.name] = smart.structBuilder(
					pConstants.RTYPE_P_COLUMN_DATA_RESOURCE_MAP_PARTITIONED,
					json.encode({
						partitionKeyLength: groupKeyLength,
						keyLength: output.keyLength
					})
				)
			} else if output.type == "JsonPartitioned" {
				outputMaps[output.name] = smart.structBuilder(
					pConstants.RTYPE_P_COLUMN_DATA_JSON_SUPER_PARTITIONED,
					json.encode({
						superPartitionKeyLength: groupKeyLength,
						partitionKeyLength: output.partitionKeyLength
					})
				)
			} else if output.type == "BinaryPartitioned" {
				outputMaps[output.name] = smart.structBuilder(
					pConstants.RTYPE_P_COLUMN_DATA_BINARY_SUPER_PARTITIONED,
					json.encode({
						superPartitionKeyLength: groupKeyLength,
						partitionKeyLength: output.partitionKeyLength
					})
				)
			} else if output.type == "Xsv" {
				// each field will contain super-partitioned data for the corresponding column
				// (specs must be added on the higher level to make a pframe)
				map := {}
				for column in output.settings.columns {
					id := pUtil.xsvColumnId(column)
					map[id] = {} // partKey -> partitioned data resource ref (not-super-partitioned)
				}
				outputMaps[output.name] = map
			} else {
				ll.panic("unknonw output type: %v", output.type)
			}
		}

		for sGroupKey, group in groups {
			group = group.lockAndBuild()
			renderInputs := {}
			renderInputs[pConstants.KEY_FIELD_NAME] = json.decode(sGroupKey)
			renderInputs[pConstants.VALUE_FIELD_NAME] = group
			for name, field in extraInputs {
				renderInputs[name] = field
			}
			renderResult := render.createUniversal(body, eph, renderInputs)
			for output in outputs {
				path := output.path
				if is_undefined(path) {
					path = [output.name]
				}
				ref := renderResult.output(path[0]).getFutureInputField(path[1:], eph)
				if output.type == "Xsv" {
					pf := xsv.importFile(ref, output.tsvType, output.settings, { dataOnly: true })
					for col in output.settings.columns {
						id := pUtil.xsvColumnId(col)
						data := pf.getFutureInputField(id)
						outputMaps[output.name][id][sGroupKey] = data
					}
				} else {
					outputMaps[output.name].
						createInputField(sGroupKey).
						set(ref)
				}
			}
		}

		for output in outputs {
			if output.type == "Xsv" {
				mapBuilder := smart.mapBuilder()

				dataResType := pConstants.RTYPE_P_COLUMN_DATA_JSON_SUPER_PARTITIONED
				if output.settings.storageFormat == "Binary" {
					dataResType := pConstants.RTYPE_P_COLUMN_DATA_BINARY_SUPER_PARTITIONED
				} else if output.settings.storageFormat != "Json" {
					ll.panic("Unknow storage format: %v", output.settings.storageFormat)
				}
				partitionKeyLength := 0
				if !is_undefined(output.settings.partitionKeyLength) {
					partitionKeyLength = output.settings.partitionKeyLength
				}
				dataResData := json.encode({
					superPartitionKeyLength: groupKeyLength,
					partitionKeyLength: partitionKeyLength
				})

				for col in output.settings.columns {
					id := pUtil.xsvColumnId(col)
					parts := outputMaps[output.name][id]
					dataRes := smart.structBuilder(
						dataResType, dataResData
					)
					for sGroupKey, partData in parts {
						dataRes.createInputField(sGroupKey).set(partData)
					}
					mapBuilder.add(id, dataRes.lockAndBuild())
				}

				outputMaps[output.name] = mapBuilder.build()
			} else {
				outputMaps[output.name] = outputMaps[output.name].lockAndBuild()
			}
		}

		return outputMaps
	} else {
		ll.panic("Unexpected input resource type: %v", data.info().Type)
	}
})
